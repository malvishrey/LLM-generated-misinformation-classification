{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7006601,"sourceType":"datasetVersion","datasetId":4027950}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-24T21:24:03.776660Z","iopub.execute_input":"2023-11-24T21:24:03.777808Z","iopub.status.idle":"2023-11-24T21:24:03.785135Z","shell.execute_reply.started":"2023-11-24T21:24:03.777738Z","shell.execute_reply":"2023-11-24T21:24:03.784237Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/politifact/synthetic-gpt-3.5-turbo_politifact_partially_arbitrary_generation_politics_rumors_processed.csv\n/kaggle/input/politifact/synthetic-gpt-3.5-turbo_politifact_paraphrase_generation_processed.csv\n/kaggle/input/politifact/synthetic-gpt-3.5-turbo_politifact_hallucination_processed.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:24:08.572175Z","iopub.execute_input":"2023-11-24T21:24:08.573012Z","iopub.status.idle":"2023-11-24T21:24:35.312466Z","shell.execute_reply.started":"2023-11-24T21:24:08.572977Z","shell.execute_reply":"2023-11-24T21:24:35.311337Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:24:35.314985Z","iopub.execute_input":"2023-11-24T21:24:35.315361Z","iopub.status.idle":"2023-11-24T21:24:46.980864Z","shell.execute_reply.started":"2023-11-24T21:24:35.315325Z","shell.execute_reply":"2023-11-24T21:24:46.979714Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/politifact/synthetic-gpt-3.5-turbo_politifact_paraphrase_generation_processed.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:24:46.982405Z","iopub.execute_input":"2023-11-24T21:24:46.982813Z","iopub.status.idle":"2023-11-24T21:24:47.071811Z","shell.execute_reply.started":"2023-11-24T21:24:46.982772Z","shell.execute_reply":"2023-11-24T21:24:47.071039Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, test_df, _,_ = train_test_split(df, df[\"label\"], test_size=0.2, stratify=df['label'],random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:24:47.074236Z","iopub.execute_input":"2023-11-24T21:24:47.074508Z","iopub.status.idle":"2023-11-24T21:24:47.554533Z","shell.execute_reply.started":"2023-11-24T21:24:47.074482Z","shell.execute_reply":"2023-11-24T21:24:47.553427Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n","output_type":"stream"}]},{"cell_type":"code","source":"def process_data(train_df):\n    train_data = []\n    prt = \"Given a 'passage' determine whether or not it is a piece of misinformation. Only output 'YES' or 'NO'. The 'passage' is: \"\n    for i in range(len(train_df)):\n        temp_text = prt + train_df.iloc[i]['synthetic_misinformation']\n        if(train_df.iloc[i]['label']==1):\n            temp_label = 'YES'\n        else:\n            temp_label = 'NO'\n        train_data.append({\"text\": f\"[INST] {temp_text} [/INST] {temp_label}\"})\n    return train_data","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:24:47.555658Z","iopub.execute_input":"2023-11-24T21:24:47.556062Z","iopub.status.idle":"2023-11-24T21:24:47.561930Z","shell.execute_reply.started":"2023-11-24T21:24:47.556034Z","shell.execute_reply":"2023-11-24T21:24:47.561073Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data = process_data(train_df)\ntest_data = process_data(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:24:47.563032Z","iopub.execute_input":"2023-11-24T21:24:47.563296Z","iopub.status.idle":"2023-11-24T21:24:47.624611Z","shell.execute_reply.started":"2023-11-24T21:24:47.563272Z","shell.execute_reply":"2023-11-24T21:24:47.623721Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!pip install datasets -U ","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:24:47.625703Z","iopub.execute_input":"2023-11-24T21:24:47.625985Z","iopub.status.idle":"2023-11-24T21:25:00.987375Z","shell.execute_reply.started":"2023-11-24T21:24:47.625962Z","shell.execute_reply":"2023-11-24T21:25:00.986376Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting datasets\n  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/e2/cf/db41e572d7ed958e8679018f8190438ef700aeb501b62da9e1eed9e4d69a/datasets-2.15.0-py3-none-any.whl.metadata\n  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nCollecting pyarrow-hotfix (from datasets)\n  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.10.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nCollecting huggingface-hub>=0.18.0 (from datasets)\n  Obtaining dependency information for huggingface-hub>=0.18.0 from https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl.metadata\n  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, huggingface-hub, datasets\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.17.3\n    Uninstalling huggingface-hub-0.17.3:\n      Successfully uninstalled huggingface-hub-0.17.3\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\nSuccessfully installed datasets-2.15.0 huggingface-hub-0.19.4 pyarrow-hotfix-0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"# train_data[:10]","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:25:00.988743Z","iopub.execute_input":"2023-11-24T21:25:00.989068Z","iopub.status.idle":"2023-11-24T21:25:00.993368Z","shell.execute_reply.started":"2023-11-24T21:25:00.989040Z","shell.execute_reply":"2023-11-24T21:25:00.992525Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pos_sample = train_df[train_df['label']==1]\nneg_sample = train_df[train_df['label']==0]\npos_subset = (pos_sample.sample(n=5))\nneg_subset = (neg_sample.sample(n=5))","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:25:00.994850Z","iopub.execute_input":"2023-11-24T21:25:00.995125Z","iopub.status.idle":"2023-11-24T21:25:01.012728Z","shell.execute_reply.started":"2023-11-24T21:25:00.995094Z","shell.execute_reply":"2023-11-24T21:25:01.011884Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# pos_subset.head()\ntemp_df = pd.concat([pos_subset,neg_subset])","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:25:25.077615Z","iopub.execute_input":"2023-11-24T21:25:25.078010Z","iopub.status.idle":"2023-11-24T21:25:25.083817Z","shell.execute_reply.started":"2023-11-24T21:25:25.077983Z","shell.execute_reply":"2023-11-24T21:25:25.082672Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# temp_df","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:25:25.865449Z","iopub.execute_input":"2023-11-24T21:25:25.865815Z","iopub.status.idle":"2023-11-24T21:25:25.870310Z","shell.execute_reply.started":"2023-11-24T21:25:25.865783Z","shell.execute_reply":"2023-11-24T21:25:25.869286Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_data = process_data(temp_df)\ntest_data = process_data(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:25:26.445551Z","iopub.execute_input":"2023-11-24T21:25:26.446354Z","iopub.status.idle":"2023-11-24T21:25:26.463226Z","shell.execute_reply.started":"2023-11-24T21:25:26.446319Z","shell.execute_reply":"2023-11-24T21:25:26.462285Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndataset_train = Dataset.from_list(train_data[:])","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:25:27.388337Z","iopub.execute_input":"2023-11-24T21:25:27.389008Z","iopub.status.idle":"2023-11-24T21:25:28.380634Z","shell.execute_reply.started":"2023-11-24T21:25:27.388971Z","shell.execute_reply":"2023-11-24T21:25:28.379875Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dataset_train","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:25:28.392237Z","iopub.execute_input":"2023-11-24T21:25:28.392947Z","iopub.status.idle":"2023-11-24T21:25:28.399332Z","shell.execute_reply.started":"2023-11-24T21:25:28.392919Z","shell.execute_reply":"2023-11-24T21:25:28.398307Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 10\n})"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:25:28.687751Z","iopub.execute_input":"2023-11-24T21:25:28.688097Z","iopub.status.idle":"2023-11-24T21:25:45.284127Z","shell.execute_reply.started":"2023-11-24T21:25:28.688070Z","shell.execute_reply":"2023-11-24T21:25:45.283276Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# The model that you want to train from the Hugging Face hub\nmodel_name = \"NousResearch/Llama-2-7b-chat-hf\"\n\n# The instruction dataset to use\ndataset_name = \"mlabonne/guanaco-llama2-1k\"\n\n# Fine-tuned model name\nnew_model = \"llama-2-7b-miniguanaco\"\n\n################################################################################\n# QLoRA parameters\n################################################################################\n\n# LoRA attention dimension\nlora_r = 64\n\n# Alpha parameter for LoRA scaling\nlora_alpha = 16\n\n# Dropout probability for LoRA layers\nlora_dropout = 0.1\n\n################################################################################\n# bitsandbytes parameters\n################################################################################\n\n# Activate 4-bit precision base model loading\nuse_4bit = True\n\n# Compute dtype for 4-bit base models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4)\nbnb_4bit_quant_type = \"nf4\"\n\n# Activate nested quantization for 4-bit base models (double quantization)\nuse_nested_quant = False\n\n################################################################################\n# TrainingArguments parameters\n################################################################################\n\n# Output directory where the model predictions and checkpoints will be stored\noutput_dir = \"./results\"\n\n# Number of training epochs\nnum_train_epochs = 1\n\n# Enable fp16/bf16 training (set bf16 to True with an A100)\nfp16 = False\nbf16 = False\n\n# Batch size per GPU for training\nper_device_train_batch_size = 4\n\n# Batch size per GPU for evaluation\nper_device_eval_batch_size = 4\n\n# Number of update steps to accumulate the gradients for\ngradient_accumulation_steps = 1\n\n# Enable gradient checkpointing\ngradient_checkpointing = True\n\n# Maximum gradient normal (gradient clipping)\nmax_grad_norm = 0.3\n\n# Initial learning rate (AdamW optimizer)\nlearning_rate = 2e-4\n\n# Weight decay to apply to all layers except bias/LayerNorm weights\nweight_decay = 0.001\n\n# Optimizer to use\noptim = \"paged_adamw_32bit\"\n\n# Learning rate schedule\nlr_scheduler_type = \"cosine\"\n\n# Number of training steps (overrides num_train_epochs)\nmax_steps = -1\n\n# Ratio of steps for a linear warmup (from 0 to learning rate)\nwarmup_ratio = 0.03\n\n# Group sequences into batches with same length\n# Saves memory and speeds up training considerably\ngroup_by_length = True\n\n# Save checkpoint every X updates steps\nsave_steps = 0\n\n# Log every X updates steps\nlogging_steps = 25\n\n################################################################################\n# SFT parameters\n################################################################################\n\n# Maximum sequence length to use\nmax_seq_length = None\n\n# Pack multiple short examples in the same input sequence to increase efficiency\npacking = False\n\n# Load the entire model on the GPU 0\ndevice_map = {\"\": 0}","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:25:45.286102Z","iopub.execute_input":"2023-11-24T21:25:45.286558Z","iopub.status.idle":"2023-11-24T21:25:45.296521Z","shell.execute_reply.started":"2023-11-24T21:25:45.286522Z","shell.execute_reply":"2023-11-24T21:25:45.295467Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Load tokenizer and model with QLoRA configuration\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=use_4bit,\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=use_nested_quant,\n)\n\n# Check GPU compatibility with bfloat16\nif compute_dtype == torch.float16 and use_4bit:\n    major, _ = torch.cuda.get_device_capability()\n    if major >= 8:\n        print(\"=\" * 80)\n        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n        print(\"=\" * 80)\n\n# Load base model\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=device_map\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\n# Load LLaMA tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n\n# Load LoRA configuration\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\n# Set training parameters\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    fp16=fp16,\n    bf16=bf16,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=group_by_length,\n    lr_scheduler_type=lr_scheduler_type,\n#     report_to=\"tensorboard\"\n)\n\n# Set supervised fine-tuning parameters\n# trainer = SFTTrainer(\n#     model=model,\n#     train_dataset=dataset_train,\n#     peft_config=peft_config,\n#     dataset_text_field=\"text\",\n#     max_seq_length=max_seq_length,\n#     tokenizer=tokenizer,\n#     args=training_arguments,\n#     packing=packing,\n# )\n\n# # Train model\n# trainer.train()\n\n# # Save trained model\n# trainer.model.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:25:45.297676Z","iopub.execute_input":"2023-11-24T21:25:45.298036Z","iopub.status.idle":"2023-11-24T21:29:37.349834Z","shell.execute_reply.started":"2023-11-24T21:25:45.298005Z","shell.execute_reply":"2023-11-24T21:29:37.349033Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bcb92cebaf441578f8e5542122f6b1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b548c887275f45ce8a4b5630037786eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59d0ad617b4c4d4ca2c387e205302070"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f75c9fe2cb894872ac2abcee794c37d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02ae163b73c344f3b6e734b4a81f411b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0b57b061c224cac9256e51179ca28d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/179 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8ffbfc237a047d0b995d5427349e536"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09bc9a589e0a4e488d1262b1d30280e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab9707342c414034adcb9c0f14968c8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05ff266ce7eb42bbb1d9f5cbb27f8e24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0782028c163846a6986c632a093f8fa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0ea38e16ead4f4d90f3db0697650683"}},"metadata":{}}]},{"cell_type":"code","source":"os.rename('/kaggle/working/llama-2-7b-miniguanaco/adapter_config.json', '/kaggle/working/llama-2-7b-miniguanaco/config.json')\nos.rename('/kaggle/working/llama-2-7b-miniguanaco/adapter_model.bin', '/kaggle/working/llama-2-7b-miniguanaco/pytorch_model.bin')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T00:57:53.516771Z","iopub.execute_input":"2023-11-24T00:57:53.517611Z","iopub.status.idle":"2023-11-24T00:57:53.524479Z","shell.execute_reply.started":"2023-11-24T00:57:53.517576Z","shell.execute_reply":"2023-11-24T00:57:53.523423Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/politifact/synthetic-gpt-3.5-turbo_politifact_hallucination_processed.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T22:25:03.801870Z","iopub.execute_input":"2023-11-23T22:25:03.802179Z","iopub.status.idle":"2023-11-23T22:25:03.841736Z","shell.execute_reply.started":"2023-11-23T22:25:03.802146Z","shell.execute_reply":"2023-11-23T22:25:03.840763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df_h = pd.read_csv('/kaggle/input/politifact/synthetic-gpt-3.5-turbo_politifact_partially_arbitrary_generation_politics_rumors_processed.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:29:37.352032Z","iopub.execute_input":"2023-11-24T21:29:37.352411Z","iopub.status.idle":"2023-11-24T21:29:37.373635Z","shell.execute_reply.started":"2023-11-24T21:29:37.352375Z","shell.execute_reply":"2023-11-24T21:29:37.372751Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T01:05:46.776281Z","iopub.execute_input":"2023-11-24T01:05:46.776602Z","iopub.status.idle":"2023-11-24T01:05:46.816817Z","shell.execute_reply.started":"2023-11-24T01:05:46.776575Z","shell.execute_reply":"2023-11-24T01:05:46.815768Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"             news_id                                          news_text  \\\n362   politifact1180  I am not the first President to take up this c...   \n35   politifact15301  This Account has been suspended.Contact your h...   \n27   politifact14643  SHARE this story with your friends!10.3k SHARE...   \n2    politifact13515                 See more of Sid Miller on Facebook   \n186  politifact15418  Former Secretary of State John Kerry may be he...   \n\n     label lang                                              theme  \\\n362      0   en                                                  0   \n35       1   en  This Account has been suspended.Contact your h...   \n27       1   en  SHARE this story with your friends!10.3k SHARE...   \n2        1   en                 See more of Sid Miller on Facebook   \n186      1   en  Former Secretary of State John Kerry may be he...   \n\n                              synthetic_misinformation  \n362  I am not the first President to take up this c...  \n35   Please communicate with your hosting provider ...  \n27   Please share this story with your friends! 10....  \n2    View additional content featuring Sid Miller b...  \n186  John Kerry, the former Secretary of State, may...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>news_id</th>\n      <th>news_text</th>\n      <th>label</th>\n      <th>lang</th>\n      <th>theme</th>\n      <th>synthetic_misinformation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>362</th>\n      <td>politifact1180</td>\n      <td>I am not the first President to take up this c...</td>\n      <td>0</td>\n      <td>en</td>\n      <td>0</td>\n      <td>I am not the first President to take up this c...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>politifact15301</td>\n      <td>This Account has been suspended.Contact your h...</td>\n      <td>1</td>\n      <td>en</td>\n      <td>This Account has been suspended.Contact your h...</td>\n      <td>Please communicate with your hosting provider ...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>politifact14643</td>\n      <td>SHARE this story with your friends!10.3k SHARE...</td>\n      <td>1</td>\n      <td>en</td>\n      <td>SHARE this story with your friends!10.3k SHARE...</td>\n      <td>Please share this story with your friends! 10....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>politifact13515</td>\n      <td>See more of Sid Miller on Facebook</td>\n      <td>1</td>\n      <td>en</td>\n      <td>See more of Sid Miller on Facebook</td>\n      <td>View additional content featuring Sid Miller b...</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>politifact15418</td>\n      <td>Former Secretary of State John Kerry may be he...</td>\n      <td>1</td>\n      <td>en</td>\n      <td>Former Secretary of State John Kerry may be he...</td>\n      <td>John Kerry, the former Secretary of State, may...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"supervised = []\nprompt = \"Given a 'passage' determine whether or not it is a piece of misinformation. ONLY output 'YES' or 'NO' with explaination. The 'passage' is: \"\n\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=2000)\nn = test_df[\"synthetic_misinformation\"].iloc[2]\nprint(n)\nresult = pipe(f\"<s> [INST] {prompt}{n} [/INST]\")\nresult[0]['generated_text']\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T03:16:27.869280Z","iopub.execute_input":"2023-11-24T03:16:27.869650Z","iopub.status.idle":"2023-11-24T03:22:08.177413Z","shell.execute_reply.started":"2023-11-24T03:16:27.869621Z","shell.execute_reply":"2023-11-24T03:22:08.176256Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Please share this story with your friends! 10.3k people have already shared it. Recently, Donald Trump suggested that he might end aid to Puerto Rico based on the mayor of San Juan's decision to withhold aid from other parts of the country. The governor of Puerto Rico has appreciated Donald Trump's efforts to help hurricane-affected individuals but the mayor of San Juan has not distributed supplies adequately. The mayor defended her decision by saying that the city does not have enough personnel or resources to distribute supplies nationwide. However, her colleagues didn't accept her explanation and held an emergency meeting to begin impeachment proceedings that will commence on Monday. Donald Trump has provided aid to Puerto Rico and other hurricane-affected areas more effectively than any previous presidents. Puerto Rico needs new leaders who understand and appreciate this fact before they lose the aid that they are not even required to receive.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"\"<s> [INST] Given a 'passage' determine whether or not it is a piece of misinformation. ONLY output 'YES' or 'NO' with explaination. The 'passage' is: Please share this story with your friends! 10.3k people have already shared it. Recently, Donald Trump suggested that he might end aid to Puerto Rico based on the mayor of San Juan's decision to withhold aid from other parts of the country. The governor of Puerto Rico has appreciated Donald Trump's efforts to help hurricane-affected individuals but the mayor of San Juan has not distributed supplies adequately. The mayor defended her decision by saying that the city does not have enough personnel or resources to distribute supplies nationwide. However, her colleagues didn't accept her explanation and held an emergency meeting to begin impeachment proceedings that will commence on Monday. Donald Trump has provided aid to Puerto Rico and other hurricane-affected areas more effectively than any previous presidents. Puerto Rico needs new leaders who understand and appreciate this fact before they lose the aid that they are not even required to receive. [/INST]  NO.\\n\\nThe passage contains misinformation in several aspects:\\n\\n1. Donald Trump's aid to Puerto Rico: The passage claims that Donald Trump has provided aid to Puerto Rico more effectively than any previous president. However, there have been numerous reports of inadequate and slow response to the island's needs after Hurricane Maria, including delays in delivering aid and supplies, and criticism of the federal government's response.\\n2. Mayor of San Juan's decision: The passage suggests that the mayor of San Juan has not distributed supplies adequately, but there is no evidence to support this claim. In fact, the mayor of San Juan, Carmen Yulín Cruz, has been widely praised for her efforts to coordinate relief efforts and advocate for the needs of her city and the island of Puerto Rico.\\n3. Impeachment proceedings: The passage claims that impeachment proceedings will commence on Monday, but there is no evidence to support this claim. There have been no official announcements or reports of impeachment proceedings against the mayor of San Juan.\\n4. Lack of appreciation for Donald Trump's efforts: The passage implies that the governor of Puerto Rico does not appreciate Donald Trump's efforts to help hurricane-affected individuals, but there is no evidence to support this claim. In fact, the governor of Puerto Rico, Ricardo Rosselló, has expressed gratitude for the federal government's response, including Trump's.\\n\\nIn conclusion, the passage contains several misleading or false claims, and therefore can be classified as misinformation.\""},"metadata":{}}]},{"cell_type":"code","source":"supervised = []\nprompt = \"Given a 'passage' determine whether or not it is a piece of misinformation. ONLY output 'YES' or 'NO'. The 'passage' is: \"\ncount=0\nfor n in list(test_df_h[\"synthetic misinformation\"]):\n#     print(f\"{prompt}{n}\")\n\n    pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=2000)\n    result = pipe(f\"<s> [INST] {prompt}{n} [/INST]\")\n    supervised.append(result[0]['generated_text'])\n    count+=1\n    print(count)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:29:37.374857Z","iopub.execute_input":"2023-11-24T21:29:37.375249Z","iopub.status.idle":"2023-11-24T21:37:07.528246Z","shell.execute_reply.started":"2023-11-24T21:29:37.375212Z","shell.execute_reply":"2023-11-24T21:37:07.527217Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\npip install xformers.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n","output_type":"stream"}]},{"cell_type":"code","source":"sft_res = []\nfor x in supervised:\n#     sft_res.\n    if(x[-3:].strip()=='NO'):\n        sft_res.append(0)\n    else:\n        sft_res.append(1)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:37:19.178730Z","iopub.execute_input":"2023-11-24T21:37:19.179596Z","iopub.status.idle":"2023-11-24T21:37:19.185417Z","shell.execute_reply.started":"2023-11-24T21:37:19.179554Z","shell.execute_reply":"2023-11-24T21:37:19.184402Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"sft_res","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:37:21.147911Z","iopub.execute_input":"2023-11-24T21:37:21.148782Z","iopub.status.idle":"2023-11-24T21:37:21.157832Z","shell.execute_reply.started":"2023-11-24T21:37:21.148721Z","shell.execute_reply":"2023-11-24T21:37:21.156808Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1]"},"metadata":{}}]},{"cell_type":"code","source":"test_df_h['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T20:00:56.431187Z","iopub.execute_input":"2023-11-23T20:00:56.431660Z","iopub.status.idle":"2023-11-23T20:00:56.486726Z","shell.execute_reply.started":"2023-11-23T20:00:56.431624Z","shell.execute_reply":"2023-11-23T20:00:56.485602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zero_shot","metadata":{"execution":{"iopub.status.busy":"2023-11-23T19:38:52.165518Z","iopub.execute_input":"2023-11-23T19:38:52.166518Z","iopub.status.idle":"2023-11-23T19:38:52.174496Z","shell.execute_reply.started":"2023-11-23T19:38:52.166480Z","shell.execute_reply":"2023-11-23T19:38:52.173443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy_score(test_df_h['label'].values, sft_res)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T21:37:42.098411Z","iopub.execute_input":"2023-11-24T21:37:42.099238Z","iopub.status.idle":"2023-11-24T21:37:42.107181Z","shell.execute_reply.started":"2023-11-24T21:37:42.099204Z","shell.execute_reply":"2023-11-24T21:37:42.106109Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0.99"},"metadata":{}}]},{"cell_type":"code","source":"test_df['few_shot'] = sft_res","metadata":{"execution":{"iopub.status.busy":"2023-11-23T23:00:34.165445Z","iopub.execute_input":"2023-11-23T23:00:34.165906Z","iopub.status.idle":"2023-11-23T23:00:34.173454Z","shell.execute_reply.started":"2023-11-23T23:00:34.165868Z","shell.execute_reply":"2023-11-23T23:00:34.172539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv('test_df3.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T23:00:36.821522Z","iopub.execute_input":"2023-11-23T23:00:36.822460Z","iopub.status.idle":"2023-11-23T23:00:36.854888Z","shell.execute_reply.started":"2023-11-23T23:00:36.822415Z","shell.execute_reply":"2023-11-23T23:00:36.853650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count","metadata":{"execution":{"iopub.status.busy":"2023-11-20T05:50:47.580221Z","iopub.execute_input":"2023-11-20T05:50:47.580929Z","iopub.status.idle":"2023-11-20T05:50:47.586896Z","shell.execute_reply.started":"2023-11-20T05:50:47.580894Z","shell.execute_reply":"2023-11-20T05:50:47.585828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}